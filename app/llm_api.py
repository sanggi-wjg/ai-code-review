import logging
import traceback
from typing import List, Optional, Generator, Union, Tuple

from langchain.globals import set_debug
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_ollama import ChatOllama
from pydantic import BaseModel, Field

logger = logging.getLogger(__name__)


class CodeReviewIssue(BaseModel):
    """Represents a specific issue found during code review."""

    category: str = Field(
        description="Issue category (naming/security/performance)",
        enum=["naming", "security", "performance"],
    )
    description: str = Field(
        description="Detailed description of the identified issue",
    )
    suggestion: str = Field(
        description="Concrete code suggestion for improvement, including code examples where applicable"
    )
    severity: str = Field(
        description="Issue severity level",
        enum=["low", "medium", "high"],
    )


class CodeReviewResult(BaseModel):
    """Represents the result of code review."""

    summary: str = Field(
        description="Overall summary of the code review in Korean, with detailed explanation",
        default="",
    )
    issues: List[CodeReviewIssue] = Field(
        description="List of identified issues with details",
        default_factory=list,
    )
    has_issues: bool = Field(
        description="Indicates whether any critical issues were found in the code",
        default=False,
    )
    review_status: str = Field(
        description="Overall review status",
        enum=["passed", "needs_changes", "critical_issues"],
        default="passed",
    )

    def format_to_comment(self) -> str:
        def get_severity_emoji(severity: str) -> str:
            return {
                "high": "ğŸ”´",
                "medium": "ğŸŸ¡",
                "low": "ğŸŸ¢",
            }.get(severity, "â“")

        def get_status_header(status: str) -> str:
            return {
                "passed": "# âœ… ì½”ë“œ ë¦¬ë·° ì™„ë£Œ",
                "needs_changes": "# âš ï¸ ìˆ˜ì •ì´ í•„ìš”í•œ ì‚¬í•­ì´ ìˆìŠµë‹ˆë‹¤",
                "critical_issues": "# ğŸš¨ ì¤‘ìš”í•œ ë¬¸ì œê°€ ë°œê²¬ ë˜ì—ˆìŠµë‹ˆë‹¤ ğŸš¨",
            }.get(status, "# ğŸ¤– ì½”ë“œ ë¦¬ë·° ì™„ë£Œ")

        def get_issue_category_title(category_type: str) -> str:
            return {
                "naming": "## ğŸ“ ë„¤ì´ë° ì´ìŠˆ",
                "security": "## ğŸ”’ ë³´ì•ˆ ì´ìŠˆ",
                "performance": "## âš¡ ì„±ëŠ¥ ì´ìŠˆ",
            }.get(category_type, "## ğŸœ ì´ìŠˆ")

        comment = f"{get_status_header(self.review_status)}\n\n"
        comment += f"{self.summary}\n\n"

        if not self.has_issues:
            return comment

        comment += "# ë°œê²¬ëœ ì´ìŠˆ\n\n"
        for issue in self.issues:
            comment += f"{get_issue_category_title(issue.category)}\n\n"
            comment += f"### {get_severity_emoji(issue.severity)} **ë¬¸ì œì **\n"
            comment += f"{issue.description}\n\n"
            comment += f"### ğŸ’¡ **ê°œì„  ì œì•ˆ**\n"
            comment += f"{issue.suggestion}\n\n"

        return comment


class LlmAPI:

    SYSTEM_MESSAGE_CODE_REVIEW = """
You are an expert-level code reviewer specializing in software security, performance optimization, and best coding practices. Your role is to meticulously analyze the given code changes and provide constructive feedback.

<REQUIREMENTS>
Your feedback must be **concise, clear, and actionable** to help improve the code quality. Summarize your responses to enhance readability. If issues are found, suggest specific improvements or alternative solutions.
**Always respond in Korean.** Do not use any other language unless explicitly requested.

When analyzing the code, consider the following aspects:
- Inappropriate function or variable names that are misleading, unclear, or violate naming conventions, making the code harder to understand or maintain.
- Security vulnerabilities, such as injection risks, improper authentication, data leaks, or insecure dependencies.
- Performance bottlenecks, including inefficient algorithms, redundant computations, memory leaks, or unnecessary resource usage.
- Ensure that your feedback helps developers **improve code quality while maintaining security and efficiency.
</REQUIREMENTS>

<OUTPUT_FORMAT>
You must return the output in the following structured format as a JSON object, ensuring compatibility with `langchain with_structured_output`. 

{{
  "summary": "ì½”ë“œ ë¦¬ë·°ì˜ ì „ì²´ ìš”ì•½ì„ ì œê³µí•˜ì„¸ìš”. (ì˜ˆ: ì½”ë“œê°€ ì „ë°˜ì ìœ¼ë¡œ ì¢‹ì€ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë‚˜, ë³´ì•ˆ ì·¨ì•½ì ì´ ë°œê²¬ë¨)",
  "issues": [
    {{
      "category": "naming | security | performance",
      "description": "ë°œê²¬ëœ ë¬¸ì œë¥¼ ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”.",
      "suggestion": "êµ¬ì²´ì ì¸ ì½”ë“œ ê°œì„  ë°©ë²•ì„ ì œì‹œí•˜ì„¸ìš”. í•„ìš”í•˜ë©´ ì½”ë“œ ì˜ˆì œ í¬í•¨.",
      "severity": "low | medium | high"
    }}
  ],
  "has_issues": true | false,
  "review_status": "passed | needs_changes | critical_issues"
}}
</OUTPUT_FORMAT>
""".strip()

    SYSTEM_MESSAGE_CODING_ASSIST = """
You are a highly skilled software engineer specializing in developing secure and high-performance backend systems. Your goal is to generate optimized, well-structured, and maintainable code.
Always respond in Korean. Do not use any other language unless explicitly asked.""".strip()

    @classmethod
    def chat_to_review_code(cls, changes: str) -> Optional[CodeReviewResult]:
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", cls.SYSTEM_MESSAGE_CODE_REVIEW),
                ("human", "{changes}"),
            ]
        )
        llm = ChatOllama(model="qwen2.5:14b-instruct-q8_0").with_structured_output(CodeReviewResult)
        chain = prompt | llm
        try:
            chat_response = chain.invoke({"changes": changes})
            return chat_response
            # for token in chain.stream({"changes": changes}):
            #     yield token
        except:
            traceback.print_exc()
            return None

    @classmethod
    def chat_to_ask(cls, documents: List[Tuple[Document, float]]) -> str:
        prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    """
You are a professional software engineer and an expert in code analysis and summarization.
You can quickly and accurately understand a given code and clearly summarize its core functions and behavior.
Always respond in Korean.
""".strip(),
                ),
                ("human", "Summarize the following code.\n{context}"),
            ]
        )
        llm = ChatOllama(model="exaone3.5:7.8b")
        # qa_chain = create_stuff_documents_chain(llm, prompt)
        # chain = create_retrieval_chain(retriever, qa_chain)
        # chat_response = chain.invoke({"input": search})
        context = ""
        for document, score in documents:
            with open(document.metadata["source"], "r") as f:
                context += f.read()

        chain = prompt | llm | StrOutputParser()
        chat_response = ""
        for token in chain.stream({"context": context}):
            print(token, end="", flush=True)
            chat_response += token

        logger.debug(chat_response)
        return chat_response

    @classmethod
    def chat_to_generate_code_stream(
        cls,
        documents: List[Document],
        code: str,
        consideration: str,
    ) -> Generator[str, None, None]:
        user_message = """
Please generate awesome code. I want this code:{code}.

# PROJECT SOURCE CODE SEARCH: 
{documents}
        
# CONSIDERATION: 
{consideration}""".strip()
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", cls.SYSTEM_MESSAGE_CODING_ASSIST),
                ("human", user_message),
            ]
        )
        # llm = ChatOllama(model="deepseek-coder-v2:16b")
        llm = ChatOllama(model="qwen2.5-coder:14b")
        chain = prompt | llm | StrOutputParser()

        for token in chain.stream(
            {
                "consideration": consideration,
                "documents": [doc.page_content for doc in documents],
                "code": code,
            }
        ):
            yield token
